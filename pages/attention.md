---
draft: true
aliases:
  - æ³¨æ„åŠ›
  - Attention
created: 2020-01-01T00:22:12
description: 
modified: 2025-07-19T10:06:03
tags: []
title: Attention
type:
---
# Attention

## [[machine-learning|Machine learning]]

https://en.wikipedia.org/wiki/Attention_(machine_learning)

Attention mechanism was developed to address the weaknesses of leveraging information from the hidden layers of recurrent (å¤å‘æ€§) neural networks. Recurrent neural networks favor more recent information contained in words at the end of a sentence, while information earlier in the sentence tends to be attenuated. Attention allows a token equal access to any part of a sentence directly, rather than only through the previous state.

https://en.wikipedia.org/wiki/Attention_Is_All_You_Need

## Person

æœ€è¿‘åˆ†ç¥çš„æ€ªæ¯›ç—…åˆå¼€å§‹ç¼ ä¸Šæˆ‘äº†ï¼Œå¾€å¾€æ˜¯èµ„æ–™æŸ¥åˆ°ä¸€åŠï¼Œä¼‘æ¯ç›¸å…³çš„ä¾¥å¹¸æ­¹å¿µä¸€èµ·ï¼Œå°±æ‰“å¼€äº†ä¸ç›¸å¹²çš„å†…å®¹ (Twitterï¼ŒRss)ï¼Œéº»æœ¨åœ°æ²‰æµ¸å…¶ä¸­ï¼Œè™½è¯´å¹³å‡ä¸€æ¬¡åªæœ‰äº”å…­åˆ†é’Ÿï¼Œä¹Ÿä¸é•¿ï¼Œä½†æ˜¯é¢‘ç‡å¤§äº†æ•´ä¸ªäººå›è¿‡ç¥æ¥å´å·²ç»å¿˜è®°ä¹‹å‰æ˜¯è¦åšä»€ä¹ˆçš„äº†.

æˆ‘æ—¶å¸¸æ„Ÿè§‰ [[social-media|ç¤¾äº¤åª’ä½“]] å°±æ˜¯ä¸€ä¸ªå·¨å¤§çš„é»‘æ´ï¼Œä»–çŸ¥æ™“æˆ‘å¯¹ä»€ä¹ˆæ„Ÿå…´è¶£ã€‚çŸ¥é“ä»€ä¹ˆæˆ³æˆ‘çš„ç‚¹ï¼Œæ€»æ˜¯åœ¨ç»™æˆ‘å‡ å¼ è‰²å›¾ä¹‹åå†æŠ›ç»™æˆ‘å‡ ä¸ªèµ„æºï¼Œæˆ‘ä¹åœ¨å…¶ä¸­ï¼Œå†ç­‰æˆ‘çœ‹å€¦åçªç„¶æŠ›ç»™æˆ‘ä¸€ä¼— dalao çŠ€åˆ©çš„å¤´è„‘é£æš´ï¼Œå†åº¦è†œæ‹œï¼Œå¾—ï¼Œåˆæ˜¯ä¸€æ¬¡æ€æƒ³çš„æ´—ç¤¼ğŸ˜…ã€‚æœ‰æ—¶åˆ·åˆ°ä»€ä¹ˆé‡‘å¥å°±åŒ†å¿™è®°ä¸‹ï¼Œä¹…è€Œä¹…ä¹‹è„‘è¢‹ä¸­å°±å……æ–¥ç€è¿™äº›ä¸ƒä¸ƒå…«å…«æ— ä»å¾ªè¿¹çš„å£°éŸ³ï¼Œè®©äººå¤´ç—›ä¸å·².
